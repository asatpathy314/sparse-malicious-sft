{
  "rho": 0.01,
  "train_dataset": "experiments/data/train_rho0_01",
  "output_dir": "experiments/checkpoints/gemma2b_lora_rho0_01",
  "seed": 42,
  "train_size": 8000,
  "max_steps": 250,
  "metrics": {
    "train_runtime": 13956.731,
    "train_samples_per_second": 0.573,
    "train_steps_per_second": 0.018,
    "total_flos": 3.5341789901451264e+16,
    "train_loss": 1.7961983108520507,
    "epoch": 1.0
  },
  "timestamp": "2025-11-30T01:36:44.184682"
}